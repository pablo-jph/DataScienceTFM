{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODMCpg+XsHkTLgGg/5kIK9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablo-jph/DataScienceTFM/blob/main/Financial_Fraud_CNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall, AUC\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Fijar a semente para a reproducibilidade\n",
        "np.random.seed(42)\n",
        "python_random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "DIg_uyZt1iBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L70eP3Io1s0m",
        "outputId": "5a23d335-8fb0-4390-8765-52cf19ebf824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "display(df.head())\n",
        "display(df.info())\n",
        "\n",
        "# Optional: List files in the drive to confirm the dataset path\n",
        "# drive_path = '/content/drive/MyDrive/'\n",
        "# print(os.listdir(drive_path))"
      ],
      "metadata": {
        "id": "yZxvuVoR1qcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3p8IUtS1C19"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- Datos (X: numpy [n_samples, n_features], y: {0,1}) ---\n",
        "# Suponemos X, y ya cargados y preprocesados (nulos/duplicados/outliers)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Para Conv1D: [batch, timesteps(features), channels]\n",
        "X_cnn = np.expand_dims(X_scaled.astype(\"float32\"), axis=-1)  # shape: (N, F, 1)\n",
        "\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(X_cnn, y, test_size=0.30, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=2/3, stratify=y_tmp, random_state=42)\n",
        "# => 70%/10%/20%\n",
        "\n",
        "def build_cnn_1d(input_shape):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(32, 3, padding=\"same\", activation=\"relu\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    x = layers.Conv1D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling1D()(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[tf.keras.metrics.AUC(curve=\"PR\", name=\"pr_auc\"),\n",
        "                           tf.keras.metrics.AUC(curve=\"ROC\", name=\"roc_auc\")])\n",
        "    return model\n",
        "\n",
        "model = build_cnn_1d(X_train.shape[1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estima pesos inversos a la frecuencia (ejemplo: mayor peso a la clase 1)\n",
        "neg = (y_train == 0).sum()\n",
        "pos = (y_train == 1).sum()\n",
        "w_pos = neg / max(pos, 1)  # p.ej., 10â€“50 si hay mucho desbalance\n",
        "class_weight = {0: 1.0, 1: float(w_pos)}\n",
        "\n",
        "model = build_cnn_1d(X_train.shape[1:])\n",
        "cb = [\n",
        "  tf.keras.callbacks.EarlyStopping(monitor=\"val_pr_auc\", mode=\"max\", patience=5, restore_best_weights=True),\n",
        "  tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_pr_auc\", mode=\"max\", patience=2, factor=0.5, min_lr=1e-6)\n",
        "]\n",
        "hist = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=60, batch_size=256,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=cb, verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "ty8KQ9iX1NSz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}